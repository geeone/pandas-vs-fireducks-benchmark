
# pandas-vs-fireducks-benchmark

**Testing the performance claims of FireDucks vs Pandas with large-scale DataFrame operations.**

This benchmark suite compares common DataFrame operations between Pandas and FireDucks on a synthetic dataset with **10 million+ rows** and mixed data types. The results showcase the performance difference in realistic, ETL-style scenarios.

---

## 📁 Project Structure

```bash
pandas-vs-fireducks-benchmark/
├── data/
│   ├── __init__.py
│   └── generate_dataset.py       # Script to generate synthetic 10M+ row dataset
│
├── benchmarks/
│   ├── __init__.py
│   ├── benchmark_read.py         # CSV read performance test
│   ├── benchmark_to_csv.py       # CSV write performance test
│   ├── benchmark_filter.py       # Filtering performance
│   ├── benchmark_groupby.py      # GroupBy + aggregation performance
│   ├── benchmark_sort.py         # Sorting performance
│
├── results/
│   ├── summary.csv               # Collected timing results (autogenerated)
│   └── plots/
│       └── benchmark_comparison.png  # Visual benchmark comparison chart (autogenerated)
│
├── run_all_benchmarks.py         # Master script to run all benchmark tests
├── plot_comparison.py            # Generates and saves performance comparison chart
├── requirements.txt              # Dependencies (Pandas, FireDucks, etc.)
├── README.md                     # Project overview, instructions, and analysis
└── LICENSE
```

---

## 💻 Benchmark Environment
- CPU: 4 vCPUs
- RAM: 32 GB
- OS: Ubuntu 25.04 (X86_64)
- Python: 3.13

> ⚠️ **Note:** FireDucks does **not** support Windows natively.
> To run this project on Windows, use **WSL (Windows Subsystem for Linux)** or a Linux/macOS machine.

---

## 📦 Installation

```bash
# Clone the repo
git clone https://github.com/geeone/pandas-vs-fireducks-benchmark.git
cd pandas-vs-fireducks-benchmark

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## 🧪 Running Benchmarks

### 1️⃣ Generate the synthetic dataset
```bash
python data/generate_dataset.py
```
Creates `synthetic_data.csv` (~1.5–2.5GB).

### 2️⃣ Run all benchmarks
```bash
python run_all_benchmarks.py
```
This generates `results/summary.csv` with timing results.

### 3️⃣ Plot the results
```bash
python plot_comparison.py
```
Creates `results/plots/benchmark_comparison.png`

---

## 🧠 Benchmarked Operations

| Operation        | Pandas (s) | FireDucks (s) | Speedup         |
|------------------|------------|---------------|-----------------|
| `read_csv`       | 37.66      | 0.0106        | ~3,500× faster |
| `to_csv`         | 79.86      | 6.39          | ~12× faster     |
| `filter_age>40`  | 0.71       | 0.0004        | ~1,700× faster |
| `groupby mean()` | 0.77       | 0.0008        | ~950× faster   |
| `sort_values`    | 6.00       | 0.0003        | ~20,000× faster|

📊 **Visual Chart:** See `results/plots/benchmark_comparison.png`

---

## 📌 Requirements

```txt
pandas
fireducks
faker
numpy
matplotlib
seaborn
psutil
tqdm
```

---

## 🙌 Contributing

Pull requests are welcome if you’d like to add more benchmark cases, expand dataset variety, or improve automation.

---

## 📄 License
[MIT License](https://github.com/geeone/pandas-vs-fireducks-benchmark/blob/main/LICENSE) — use it, modify it, and share it.

---

## 🔗 Author
Created by [Sergei Denisenko](https://github.com/geeone)  
Let me know if you used this project in your article, blog post, or benchmark suite!
